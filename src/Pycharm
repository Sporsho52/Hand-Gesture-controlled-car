import cv2
import mediapipe as mp
import requests
import time

ESP32_IP = "http://192.168.98.95"  # Replace with your ESP32 IP

mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.7)
mp_draw = mp.solutions.drawing_utils

def count_fingers(landmarks):
    tips_ids = [4, 8, 12, 16, 20]
    fingers = []

    # Thumb: compare tip and IP joint x-coordinates (for right hand only)
    fingers.append(landmarks[4].x < landmarks[3].x)

    # Other 4 fingers: tip y < pip y means finger is up
    for id in range(1, 5):
        fingers.append(landmarks[tips_ids[id]].y < landmarks[tips_ids[id] - 2].y)

    return fingers  # List of 5 booleans: [thumb, index, middle, ring, pinky]

def detect_tilt(landmarks):
    wrist = landmarks[0]
    index_base = landmarks[5]
    dx = index_base.x - wrist.x
    if dx > 0.08:
        return 'RIGHT'
    elif dx < -0.08:
        return 'LEFT'
    return None

def detect_gesture(landmarks):
    fingers = count_fingers(landmarks)
    total_fingers = fingers.count(True)

    if total_fingers == 1 and fingers[1]:
        return 'FORWARD'
    elif total_fingers == 2 and fingers[1] and fingers[2]:
        return 'BACKWARD'
    elif total_fingers == 5:
        return 'STOP'
    else:
        tilt = detect_tilt(landmarks)
        if tilt:
            return tilt
        else:
            return 'STOP'

def send_command(command):
    try:
        print(f"Sending command: {command}")
        requests.get(f"{ESP32_IP}/{command.lower()}", timeout=0.5)
    except requests.exceptions.RequestException as e:
        print(f"Request failed: {e}")

cap = cv2.VideoCapture(0)
prev_command = ""
last_sent = time.time()

while True:
    ret, img = cap.read()
    if not ret:
        break

    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    results = hands.process(img_rgb)

    if results.multi_hand_landmarks:
        for handLms in results.multi_hand_landmarks:
            mp_draw.draw_landmarks(img, handLms, mp_hands.HAND_CONNECTIONS)
            landmarks = [lm for lm in handLms.landmark]
            command = detect_gesture(landmarks)

            if command != prev_command and time.time() - last_sent > 1:
                send_command(command)
                prev_command = command
                last_sent = time.time()

    cv2.imshow("Hand Control", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

hands.close()
cap.release()
cv2.destroyAllWindows()
